import os
import getpass
import time
import logging
import paramiko
import tempfile
import sys
import uuid

# Determine base directory (this fileâ€™s folder) and project root (parent of BASE_DIR)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)

# Ensure local logs directory always exists
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# Local file to store the generated UUID for this user, placed in project root
UUID_FILE = os.path.join(BASE_DIR, "uuid.txt")

# Define the path for the shared log file which is assumed to be generated by log_generator.py.
SHARED_LOG_FILE = os.path.join(LOG_DIR, "threats.log")
# Define the file that stores the last read offset of the shared log file to ensure incremental uploads.
UPLOAD_OFFSET_FILE = os.path.join(LOG_DIR, "upload_offset.txt")

# Define the SSH private key path using the current user's home directory.
HOME_DIR = os.path.expanduser("~")
PRIVATE_KEY_PATH = os.path.join(HOME_DIR, ".ssh", f"id_rsa_{getpass.getuser()}")

# SFTP configuration details.
PORT = 22
SFTP_USERNAME = "logsink"
REMOTE_BASE_DIR = "PSWatchdog"

# Setup basic logging configuration for uploader operations.
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("UploaderLogger")


def load_last_offset():
    """
    Load the last read offset from UPLOAD_OFFSET_FILE.
    Returns 0 if the offset file does not exist or an error occurs.
    """
    try:
        with open(UPLOAD_OFFSET_FILE, "r") as f:
            offset = int(f.read().strip())
            logger.debug("Loaded last offset: %d", offset)
            return offset
    except Exception as e:
        logger.debug("Failed to load last offset, defaulting to 0: %s", e)
        return 0


def save_last_offset(offset):
    """
    Save the current log offset to UPLOAD_OFFSET_FILE to resume uploading from the correct position.
    """
    try:
        with open(UPLOAD_OFFSET_FILE, "w") as f:
            f.write(str(offset))
        logger.debug("Saved new offset: %d", offset)
    except Exception as e:
        logger.error("Failed to save offset: %s", e)


def get_new_log_entries():
    """
    Read new entries from the shared log file starting from the last recorded offset.
    Returns the new data and the updated offset.
    """
    last_offset = load_last_offset()
    if not os.path.exists(SHARED_LOG_FILE):
        logger.warning("Shared log file not found at %s", SHARED_LOG_FILE)
        return "", last_offset
    try:
        with open(SHARED_LOG_FILE, "r", encoding="utf-8") as f:
            f.seek(last_offset)
            new_data = f.read()
            new_offset = f.tell()
        logger.debug("Read new log entries from offset %d to %d", last_offset, new_offset)
        return new_data, new_offset
    except Exception as e:
        logger.error("Error while reading log entries: %s", e)
        return "", last_offset

def get_or_create_uuid(server_ip):
    """
    Retrieve or generate a unique user UUID for SFTP uploads.
    Reuses a locally stored UUID if available; otherwise connects to the remote host
    to avoid collisions, saves it locally, and returns the UUID string.
    """
    # If a UUID has already been stored locally, reuse it
    if os.path.exists(UUID_FILE):
        return open(UUID_FILE, "r").read().strip()

    # Load SSH key and establish SFTP connection to check existing remote directories
    try:
        private_key = paramiko.RSAKey(filename=PRIVATE_KEY_PATH)
        transport = paramiko.Transport((server_ip, PORT))
        transport.connect(username=SFTP_USERNAME, pkey=private_key)
        sftp = paramiko.SFTPClient.from_transport(transport)
    except Exception as e:
        logger.exception("Failed to connect via SFTP for UUID generation: %s", e)
        raise

    try:
        user = getpass.getuser()
        # Attempt to generate a UUID4 that doesn't collide with existing remote dirs
        while True:
            candidate = str(uuid.uuid4())
            remote_dir = f"{REMOTE_BASE_DIR}/{user}_{candidate}"
            try:
                sftp.stat(remote_dir)
                logger.warning("Collision detected for UUID %s, regenerating", candidate)
            except FileNotFoundError:
                # No collision, break out
                break

        # Persist the chosen UUID locally for future runs
        with open(UUID_FILE, "w") as f:
            f.write(candidate)
        logger.info("Generated and stored user UUID: %s", candidate)
        return candidate

    finally:
        sftp.close()
        transport.close()


def init_sftp(user, server_ip):
    """
    One-time SFTP initialization at startup:
      1) Ensures UUID exists (or is generated).
      2) Creates the remote user directory on the server if missing.
    """
    uuid_str = get_or_create_uuid(server_ip)
    remote_dir = f"{REMOTE_BASE_DIR}/{user}_{uuid_str}"

    try:
        private_key = paramiko.RSAKey(filename=PRIVATE_KEY_PATH)
        transport = paramiko.Transport((server_ip, PORT))
        transport.connect(username=SFTP_USERNAME, pkey=private_key)
        sftp = paramiko.SFTPClient.from_transport(transport)

        try:
            sftp.stat(remote_dir)
            logger.debug("Remote user directory already exists: %s", remote_dir)
        except FileNotFoundError:
            sftp.mkdir(remote_dir)
            logger.info("Created remote user directory: %s", remote_dir)
    except Exception as e:
        logger.error("Error during SFTP init: %s", e)
        raise
    finally:
        try:
            sftp.close()
            transport.close()
        except:
            pass


def upload_data(data, remote_file_path, server_ip, server_port):
    """
    Upload the provided data to the remote server via SFTP.
    The data is first written to a temporary file. If any step fails, the temporary file is removed.
    """
    if not data:
        logger.info("No new log entries to upload.")
        return
    try:
        with tempfile.NamedTemporaryFile("w", encoding="utf-8", delete=False, dir=LOG_DIR, suffix=".log") as tmp_file:
            tmp_file.write(data)
            tmp_file_path = tmp_file.name
        logger.debug("Temporary file created at %s", tmp_file_path)
    except Exception as e:
        logger.error("Failed to create temporary file: %s", e)
        return

    if not os.path.exists(PRIVATE_KEY_PATH):
        logger.error("Private key does not exist at %s", PRIVATE_KEY_PATH)
        os.remove(tmp_file_path)
        return
    try:
        private_key = paramiko.RSAKey(filename=PRIVATE_KEY_PATH)
    except Exception as e:
        logger.exception("Failed to load the private key: %s", e)
        os.remove(tmp_file_path)
        return

    try:
        transport = paramiko.Transport((server_ip, PORT))
        transport.connect(username=SFTP_USERNAME, pkey=private_key)
        sftp = paramiko.SFTPClient.from_transport(transport)
    except Exception as e:
        logger.exception("Failed to establish SFTP connection: %s", e)
        os.remove(tmp_file_path)
        return

    user_dir = os.path.dirname(remote_file_path)
    try:
        sftp.stat(user_dir)
    except FileNotFoundError:
        try:
            sftp.mkdir(user_dir)
            logger.info("Created remote user directory: %s", user_dir)
        except Exception as e:
            logger.error("Failed to create remote directory %s: %s", user_dir, e)
            sftp.close()
            transport.close()
            os.remove(tmp_file_path)
            return

    try:
        sftp.put(tmp_file_path, remote_file_path)
        logger.info("Uploaded logs to %s", remote_file_path)
    except Exception as e:
        logger.error("Failed to upload file: %s", e)
    finally:
        sftp.close()
        transport.close()
        os.remove(tmp_file_path)


def upload_files(server_ip, server_port=PORT):
    """
    Main function for the upload task.
    Gathers new log entries, constructs a unique remote file name based on the current timestamp,
    uploads the log entries, and then saves the new file offset.
    """
    logger.info("Running upload job for server: %s", server_ip)
    data, new_offset = get_new_log_entries()

    if data:
        user = getpass.getuser()
        uuid_str = get_or_create_uuid(server_ip)
        remote_user_dir = f"{REMOTE_BASE_DIR}/{user}_{uuid_str}"

        timestamp = time.strftime("%Y-%m-%dT%H:%M:%S")

        remote_file = f"{user}_{timestamp}_threats.log"
        remote_file_path = f"{remote_user_dir}/{remote_file}"

        upload_data(data, remote_file_path, server_ip, server_port)
        save_last_offset(new_offset)
    else:
        logger.debug("No new entries to upload at this time.")
